{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, multiply, concatenate, Activation, Masking, Reshape,RepeatVector,TimeDistributed\n",
    "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout,GlobalMaxPooling1D\n",
    "\n",
    "from utils.data_split import split_sequence_parallel\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 不加这几句，则CONV 报错\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\桌面\\空气质量预测综合\\北京多站点空气质量数据集\\北京天坛\\\\InfoGainTiantandata.csv\", header=0,infer_datetime_format=True, engine='python')\n",
    "data['Unnamed: 0']=pd.to_datetime(data['Unnamed: 0'])\n",
    "data.set_index(\"Unnamed: 0\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "归一化\n",
    "'''\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler1 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler3 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler4 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler5 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler6 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler7 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler8 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler9 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler10 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler11 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler12 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler13 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler14 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler15 = MinMaxScaler(feature_range=(0, 1))\n",
    "data_minmax = data.copy()\n",
    "data_minmax['PM2.5']=scaler1.fit_transform(data_minmax['PM2.5'].values.reshape(-1,1))\n",
    "data_minmax['PM10']=scaler2.fit_transform(data_minmax['PM10'].values.reshape(-1,1))\n",
    "data_minmax['SO2']=scaler3.fit_transform(data_minmax['SO2'].values.reshape(-1,1))\n",
    "data_minmax['NO2']=scaler4.fit_transform(data_minmax['NO2'].values.reshape(-1,1))\n",
    "data_minmax['CO']=scaler5.fit_transform(data_minmax['CO'].values.reshape(-1,1))\n",
    "data_minmax['O3']=scaler6.fit_transform(data_minmax['O3'].values.reshape(-1,1))\n",
    "data_minmax['TEMP']=scaler7.fit_transform(data_minmax['TEMP'].values.reshape(-1,1))\n",
    "data_minmax['PRES']=scaler8.fit_transform(data_minmax['PRES'].values.reshape(-1,1))\n",
    "data_minmax['DEWP']=scaler9.fit_transform(data_minmax['DEWP'].values.reshape(-1,1))\n",
    "data_minmax['wd_E']=scaler10.fit_transform(data_minmax['wd_E'].values.reshape(-1,1))\n",
    "data_minmax['wd_ENE']=scaler11.fit_transform(data_minmax['wd_ENE'].values.reshape(-1,1))\n",
    "data_minmax['wd_ESE']=scaler12.fit_transform(data_minmax['wd_ESE'].values.reshape(-1,1))\n",
    "data_minmax['wd_NE']=scaler13.fit_transform(data_minmax['wd_NE'].values.reshape(-1,1))\n",
    "data_minmax['wd_NW']=scaler14.fit_transform(data_minmax['wd_NW'].values.reshape(-1,1))\n",
    "data_minmax['wd_SW']=scaler15.fit_transform(data_minmax['wd_SW'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7320, 15), (1464, 15))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "取一年的时间，10个月做训练和验证，2个月做测试\n",
    "'''\n",
    "cast1 = -10200\n",
    "cast2 = -2880\n",
    "cast3 = -1416                                                                      \n",
    "data_train = data_minmax[cast1:cast2]\n",
    "data_test = data_minmax[cast2:cast3] \n",
    "data_train.shape,data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7320, 15), (1464, 15))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = np.array(data_test)\n",
    "data_train = np.array(data_train)\n",
    "data_train.shape,data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_width = 21\n",
    "pred_length = 12\n",
    "verbose_set = 2\n",
    "X, y, features = split_sequence_parallel(data_train,sw_width,pred_length)\n",
    "test_x,test_y,test_features = split_sequence_parallel(data_test,sw_width,pred_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ED_LSTM_model():\n",
    "#     ip = Input(shape=(MAX_NB_VARIABLES, MAX_TIMESTEPS))\n",
    "    ip = Input(shape=(sw_width,features))\n",
    "\n",
    "    x = LSTM(128,activation=\"relu\")(ip)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    x = RepeatVector(pred_length)(x)\n",
    "    x = LSTM(64,activation=\"relu\",return_sequences=True)(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    \n",
    "    \n",
    "    out = TimeDistributed(Dense(1))(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 21, 15)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               73728     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 12, 64)            49408     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 12, 1)             65        \n",
      "=================================================================\n",
      "Total params: 123,201\n",
      "Trainable params: 123,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1efd9212f28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ED_LSTM_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(y.shape[0],y.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5466 samples, validate on 1822 samples\n",
      "Epoch 1/70\n",
      " - 6s - loss: 0.0586 - val_loss: 0.0400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03999, saving model to D:\\桌面\\空气质量预测综合\\北京多站点空气质量数据集\\北京天坛\\12hourweights\\encoder_decoder_weights_best.hdf5\n",
      "Epoch 2/70\n",
      " - 5s - loss: 0.0525 - val_loss: 0.0389\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03999 to 0.03887, saving model to D:\\桌面\\空气质量预测综合\\北京多站点空气质量数据集\\北京天坛\\12hourweights\\encoder_decoder_weights_best.hdf5\n",
      "Epoch 3/70\n",
      " - 5s - loss: 0.0504 - val_loss: 0.0399\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03887\n",
      "Epoch 4/70\n",
      " - 5s - loss: 0.0485 - val_loss: 0.0394\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03887\n",
      "Epoch 5/70\n",
      " - 5s - loss: 0.0463 - val_loss: 0.0429\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03887\n",
      "Epoch 6/70\n",
      " - 5s - loss: 0.0456 - val_loss: 0.0472\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03887\n",
      "Epoch 7/70\n",
      " - 5s - loss: 0.0449 - val_loss: 0.0398\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03887\n",
      "Epoch 8/70\n",
      " - 5s - loss: 0.0427 - val_loss: 0.0428\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03887\n",
      "Epoch 9/70\n",
      " - 5s - loss: 0.0404 - val_loss: 0.0467\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03887\n",
      "Epoch 10/70\n",
      " - 5s - loss: 0.0384 - val_loss: 0.0464\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03887\n",
      "Epoch 11/70\n",
      " - 5s - loss: 0.0378 - val_loss: 0.0427\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.03887\n",
      "Epoch 12/70\n",
      " - 5s - loss: 0.0358 - val_loss: 0.0459\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.03887\n",
      "Epoch 13/70\n",
      " - 5s - loss: 0.0349 - val_loss: 0.0424\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.03887\n",
      "Epoch 14/70\n",
      " - 5s - loss: 0.0329 - val_loss: 0.0440\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03887\n",
      "Epoch 15/70\n",
      " - 5s - loss: 0.0330 - val_loss: 0.0437\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03887\n",
      "Epoch 16/70\n",
      " - 5s - loss: 0.0311 - val_loss: 0.0463\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.03887\n",
      "Epoch 17/70\n",
      " - 5s - loss: 0.0296 - val_loss: 0.0443\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.03887\n",
      "Epoch 18/70\n",
      " - 5s - loss: 0.0289 - val_loss: 0.0437\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.03887\n",
      "Epoch 19/70\n",
      " - 5s - loss: 0.0283 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.03887\n",
      "Epoch 20/70\n",
      " - 5s - loss: 0.0280 - val_loss: 0.0452\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.03887\n",
      "Epoch 21/70\n",
      " - 5s - loss: 0.0263 - val_loss: 0.0471\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.03887\n",
      "Epoch 22/70\n",
      " - 5s - loss: 0.0248 - val_loss: 0.0471\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.03887\n",
      "Epoch 23/70\n",
      " - 5s - loss: 0.0243 - val_loss: 0.0473\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03887\n",
      "Epoch 24/70\n",
      " - 5s - loss: 0.0238 - val_loss: 0.0476\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03887\n",
      "Epoch 25/70\n",
      " - 5s - loss: 0.0231 - val_loss: 0.0475\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.03887\n",
      "Epoch 26/70\n",
      " - 5s - loss: 0.0230 - val_loss: 0.0454\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03887\n",
      "Epoch 27/70\n",
      " - 5s - loss: 0.0225 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03887\n",
      "Epoch 28/70\n",
      " - 5s - loss: 0.0224 - val_loss: 0.0466\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03887\n",
      "Epoch 29/70\n",
      " - 5s - loss: 0.0212 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03887\n",
      "Epoch 30/70\n",
      " - 5s - loss: 0.0216 - val_loss: 0.0459\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03887\n",
      "Epoch 31/70\n",
      " - 5s - loss: 0.0211 - val_loss: 0.0443\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.03887\n",
      "Epoch 32/70\n",
      " - 5s - loss: 0.0201 - val_loss: 0.0480\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03887\n",
      "Epoch 33/70\n",
      " - 5s - loss: 0.0197 - val_loss: 0.0459\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03887\n",
      "Epoch 34/70\n",
      " - 5s - loss: 0.0197 - val_loss: 0.0458\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03887\n",
      "Epoch 35/70\n",
      " - 5s - loss: 0.0191 - val_loss: 0.0468\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03887\n",
      "Epoch 36/70\n",
      " - 5s - loss: 0.0194 - val_loss: 0.0467\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03887\n",
      "Epoch 37/70\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0454\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03887\n",
      "Epoch 38/70\n",
      " - 5s - loss: 0.0187 - val_loss: 0.0473\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03887\n",
      "Epoch 39/70\n",
      " - 5s - loss: 0.0184 - val_loss: 0.0464\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03887\n",
      "Epoch 40/70\n",
      " - 5s - loss: 0.0184 - val_loss: 0.0456\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03887\n",
      "Epoch 41/70\n",
      " - 5s - loss: 0.0181 - val_loss: 0.0461\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03887\n",
      "Epoch 42/70\n",
      " - 5s - loss: 0.0179 - val_loss: 0.0471\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03887\n",
      "Epoch 43/70\n",
      " - 5s - loss: 0.0181 - val_loss: 0.0457\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03887\n",
      "Epoch 44/70\n",
      " - 5s - loss: 0.0179 - val_loss: 0.0452\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03887\n",
      "Epoch 45/70\n",
      " - 5s - loss: 0.0176 - val_loss: 0.0467\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03887\n",
      "Epoch 46/70\n",
      " - 5s - loss: 0.0170 - val_loss: 0.0448\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03887\n",
      "Epoch 47/70\n",
      " - 5s - loss: 0.0168 - val_loss: 0.0459\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03887\n",
      "Epoch 48/70\n",
      " - 5s - loss: 0.0167 - val_loss: 0.0469\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03887\n",
      "Epoch 49/70\n",
      " - 5s - loss: 0.0164 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03887\n",
      "Epoch 50/70\n",
      " - 5s - loss: 0.0171 - val_loss: 0.0467\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03887\n",
      "Epoch 51/70\n",
      " - 5s - loss: 0.0164 - val_loss: 0.0453\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.03887\n",
      "Epoch 52/70\n",
      " - 5s - loss: 0.0161 - val_loss: 0.0455\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.03887\n",
      "Epoch 53/70\n",
      " - 5s - loss: 0.0161 - val_loss: 0.0467\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.03887\n",
      "Epoch 54/70\n",
      " - 5s - loss: 0.0156 - val_loss: 0.0455\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.03887\n",
      "Epoch 55/70\n",
      " - 5s - loss: 0.0174 - val_loss: 0.0447\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.03887\n",
      "Epoch 56/70\n",
      " - 5s - loss: 0.0156 - val_loss: 0.0446\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.03887\n",
      "Epoch 57/70\n",
      " - 5s - loss: 0.0157 - val_loss: 0.0459\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.03887\n",
      "Epoch 58/70\n",
      " - 5s - loss: 0.0155 - val_loss: 0.0456\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.03887\n",
      "Epoch 59/70\n",
      " - 5s - loss: 0.0158 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.03887\n",
      "Epoch 60/70\n",
      " - 5s - loss: 0.0153 - val_loss: 0.0463\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.03887\n",
      "Epoch 61/70\n",
      " - 5s - loss: 0.0150 - val_loss: 0.0446\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.03887\n",
      "Epoch 62/70\n",
      " - 5s - loss: 0.0153 - val_loss: 0.0462\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.03887\n",
      "Epoch 63/70\n",
      " - 5s - loss: 0.0152 - val_loss: 0.0455\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.03887\n",
      "Epoch 64/70\n",
      " - 5s - loss: 0.0151 - val_loss: 0.0465\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.03887\n",
      "Epoch 65/70\n",
      " - 5s - loss: 0.0154 - val_loss: 0.0448\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.03887\n",
      "Epoch 66/70\n",
      " - 5s - loss: 0.0142 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.03887\n",
      "Epoch 67/70\n",
      " - 5s - loss: 0.0148 - val_loss: 0.0462\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.03887\n",
      "Epoch 68/70\n",
      " - 5s - loss: 0.0146 - val_loss: 0.0449\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.03887\n",
      "Epoch 69/70\n",
      " - 5s - loss: 0.0145 - val_loss: 0.0452\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.03887\n",
      "Epoch 70/70\n",
      " - 5s - loss: 0.0142 - val_loss: 0.0458\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.03887\n",
      "程序运行时间为：350.2711 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler,ReduceLROnPlateau\n",
    "\n",
    "# lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "# lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "#                                cooldown=0,\n",
    "#                                patience=5,\n",
    "#                                min_lr=0.5e-6)\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "filepath = \"D:\\桌面\\空气质量预测综合\\北京多站点空气质量数据集\\北京天坛\\\\12hourweights\\encoder_decoder_weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "starttime=time.time()\n",
    "model.compile(loss=root_mean_squared_error, optimizer='adam')\n",
    "history1 = model.fit(X,y,validation_split=0.25,epochs=70, batch_size=32,callbacks=callbacks_list, verbose=2)\n",
    "endtime=time.time()\n",
    "dtime=endtime-starttime\n",
    "print(\"程序运行时间为：%.8s s\" % dtime)  #时间显示到微秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_y.reshape(test_y.shape[0],test_y.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict(test_x)\n",
    "predict=scaler1.inverse_transform(predict.reshape(predict.shape[0],predict.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.51058292038064\n",
      "39.93454304363733\n",
      "63.05240234043444\n",
      "59.599364880618104\n"
     ]
    }
   ],
   "source": [
    "print(tf.sqrt(tf.losses.mean_squared_error(predict[:,:6],scaler1.inverse_transform(test_y.reshape(test_y.shape[0],test_y.shape[1]))[:,:6])).numpy().mean())\n",
    "print(tf.losses.mae(predict[:,:6],scaler1.inverse_transform(test_y.reshape(test_y.shape[0],test_y.shape[1]))[:,:6]).numpy().mean())\n",
    "print(tf.sqrt(tf.losses.mean_squared_error(predict[:,6:],scaler1.inverse_transform(test_y.reshape(test_y.shape[0],test_y.shape[1]))[:,6:])).numpy().mean())\n",
    "print(tf.losses.mae(predict[:,6:],scaler1.inverse_transform(test_y.reshape(test_y.shape[0],test_y.shape[1]))[:,6:]).numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
